# R programming basics {.unnumbered}

## Introduction to programming in R

There are tons of great resources for learning R. [R for Data Science](https://r4ds.had.co.nz/)
is probably the most popular resource for new useRs to get up to speed with slicing 
and dicing data in R. The *R for Data Science* book, however, is taught from the 
perspective of the [Tidyverse](https://www.tidyverse.org/). The *Tidyverse* is 
an opinionated set of packages and functions that help users perform data 
manipulations primarily on data.frames. While these packages and functions can be
great for experienced users by providing ergonomic and consistent interfaces for
data.frame manipulation, it is my personal belief that new users should first 
learn the base language, especially if their goal is to perform bioinformatics 
analysis. 

Bioinformatics tools rely heavily on subsetting and matrix manipulations. 
In my experience, users who start learning R using only function from the 
*Tidyverse* have a difficult time understanding matrix manipulations and 
subsetting operations common in bioinformatics workflows. This becomes 
especially important when using [SummarizedExperiments](https://www.bioconductor.org/packages/devel/bioc/vignettes/SummarizedExperiment/inst/doc/SummarizedExperiment.html) - the backbone of many bioinformatics data structures in 
R. 

For this reason, we're going to focus on learning R from the ground up using 
functions that exist primarily in the base language. A great resource for 
learning base R quickly is Norm Matloff's *fasteR* which can be found 
[here](https://github.com/matloff/fasteR). 

## Subsetting in R

You may have only ever encountered R from the perspective of the 
[tidyverse](https://www.tidyverse.org/). `tidyverse` functions provide useful 
abstractions for munging [tidy data](https://vita.had.co.nz/papers/tidy-data.html)
however, most genomics data is often best represented and operated on as 
matrices. Keeping your data in matrix format can provide many benefits as far 
as speed and code clarity, which in turn helps to ensure correctness. You can 
think of matrices as just fancy 2D versions of vectors. So what are vectors?

Vectors are the main building blocks of most R analyses. Whenever you use the
`c()` function ('concatenate'), like: `x <- c('a', 'b', 'c')` you're creating a
vector. Vectors hold R objects and are the building block of more complex 
structures in R.

NOTE: the following is heavily inspired by Norm Matloff's excellent 
[fasteR](https://github.com/matloff/fasteR) tutorial. Take a look there to get a 
brief and concise overview base R. You should also check out the first few 
chapters of Hadley Wickham's amazing book [Advanced R](https://adv-r.hadley.nz/).
The [first edition](http://adv-r.had.co.nz/) contains some more information on
base R.

### Subsetting vectors

Below, we'll use the built-in R constant called `LETTERS`. The `LETTERS` 
vector is simply a 'list' of all uppercase letters in the Roman alphabet.

```{r}
LETTERS
```

We can subset the vector by position. For example, to get the 3rd letter we use
the `[` operator and the position we want to extract.

```{r}
LETTERS[3]
```

We can also use a range of positions. The notation `3:7` is a shortcut that
generates the numbers, 3, 4, 5, 6, 7. 

```{r}
LETTERS[3:7]
```

We don't have to select sequential elements either. We can extract elements by
using another vector of positions.

```{r}
LETTERS[c(7, 5, 14, 14, 1, 18, 15)]
```

Vectors become really powerful when we start combining them with logical 
operations. R supports all of the usual logical and mathematical operators 
you can expect from a programming language, `<`, `>`, `==`, `<=`, `>=`, `%in%`, 
etc.

```{r}
my_favorite_letters <- c("A", "B", "C")

# See that this produces a logical vector of (TRUE/FALSE) values
# TRUE when LETTERS is one of my_favorite_letters and FALSE otherwise
LETTERS %in% my_favorite_letters

# We can use that same expression to filter the vector
LETTERS[LETTERS %in% my_favorite_letters]
```

This same kind of subsetting works on vectors that contain numeric data as well. 
For example, we can filter the measurements of annual flow of water through the 
Nile river like so:

*Nile is another built-in dataset*

```{r}
# Any values strictly greater than 1200
Nile[Nile > 1200]

# Any even number - `%%` is the modulus operator
Nile[Nile %% 2 == 0]
```

### Subsetting data.frames

But these are just one dimensional vectors. In R, we usually deal with 
data.frames (tibbles for you tidyverse folks) and matrices. Lucky for us, the 
subsetting operations we learned for vectors work the same way for data.frames
and matrices.

Let's take a look at the built-in `ToothGrowth` dataset. The data consists of 
the length of odontoblasts in 60 guinea pigs receiving one of three levels of 
vitamin C by one of two delivery methods.

```{r}
head(ToothGrowth)
```

The dollar sign `$` is used to extract an individual column from the data.frame, 
which is just a vector.

```{r}
head(ToothGrowth$len)
```

We can also use the `[[` to get the same thing. Double-brackets come in handy 
when your columns are not valid R names since `$` only works when columns are 
valid names.

```{r}
head(ToothGrowth[["len"]])
```

When subsetting a data.frame in base R, the general scheme is:

```
df[the rows you want, the columns you want]
```

So in order to get the 5th row of the first column we could do:

```{r}
ToothGrowth[5, 1]
```

Again, we can combine this kind of thinking to extract rows and columns matching
logical conditions. For example, if we want to get all of the animals 
administered orange juice ('OJ')

```{r}
ToothGrowth[ToothGrowth$supp == "OJ", ]
```

We can also combine logical statements. For example, to get all of the rows for 
animals administered orange juice and with odontoblast length ('len') less than 
10.

```{r}
ToothGrowth[ToothGrowth$supp == "OJ" & ToothGrowth$len < 10, ]

# We can also use the bracket notation to select rows and columns at the same time
# Although this gets a little difficult to read
ToothGrowth[ToothGrowth$supp == "OJ" & ToothGrowth$len < 10, c("len", "supp")]
```

It gets annoying typing `ToothGrowth` every time we want to subset the data.frame. 
Base R has a very useful function called `subset()` that can help us type less.
`subset()` essentially 'looks inside' the data.frame for the given columns and 
evaluates the expression without having to explicitly tell R where to find the 
columns. Think of it like `dplyr::filter()`, if you are familiar with that 
function. 

```{r}
subset(ToothGrowth, supp == "OJ" & len < 10)
```

### Subsetting Lists

Another data structure to be aware of, which is used frequently, is the `List`. 
We've actually already encountered Lists above. data.frames are really just 
Lists where each vector contains the same data type and all List elements are the
same length.

We can create a List in R using the `list()` function. Notice how each list 
element has a name and can contain a different type of data and number of data 
elements

```{r}
l <- list(
  element1 = c(1, 10, 12, 3, 6, 12, 13, 2, 5, 6, 3, 7),
  element2 = c("a", "b", "c"),
  element3 = c(TRUE, TRUE, FALSE, FALSE, FALSE),
  element4 = c(0.001, 0.05, 0.86, 1.098, 345.0)
)
```

Lists can be tricky at first. To extract the data from a particular list 
element you can use the `[[` or the `$` (as in the case of data.frames above). 
Like vectors, you can use either the index or the name of the element you wish 
to extract. 

```{r}
l[[1]]

l[["element1"]]

l$element1
```

What is returned if you only use the single bracket `[`? 

```{r}
l[1]
```

You get another List, but now with a single element. This behavior might seem 
unintuitive at first, but it can be very useful for creating new lists.

```{r}
numeric_l <- l[c(1, 4)]
```

### Subsetting matrices

Matrices behave much like data.frames but unlike data.frames matrices can only
contain one type of data. This might sound like a limitation at first but 
you'll soon come to realize that matrices are very powerful (and fast) to work 
with in R.

```{r}
set.seed(123)

# Create some random data that looks like methylation values
(m <- matrix(
  data = runif(6 * 10),
  ncol = 6,
  dimnames = list(
    paste0("CpG.", 1:10),
    paste0("Sample", 1:6)
  )
))
```

If we want to extract the value for CpG.3 for Sample3

```{r}
m[3, 3]
```

Or all values of CpG.3 for every sample

```{r}
m[3, ]

# Or refer to the row by it's name
m["CpG.3", ]
```

Or all CpGs for Sample3

```{r}
m[, 3]

# Or refer to the column by it's name
m[, "Sample3"]
```

We can also apply a mask to the entire matrix at once. For example, the 
following will mark any value that is greater than 0.5 with `TRUE`

```{r}
m > 0.5
```

We can use this kind of masking to filter rows of the matrix using some very 
helpful base R functions that operate on matrices. For example, to get only 
those CpGs where 3 or more samples have a value > 0.5 we can use the `rowSums()`
like so:

```{r}
m[rowSums(m > 0.5) > 3, ]
```

This pattern is very common when dealing with sequencing data. Base R functions
like `rowSums()` and `colMeans()` are specialized to operate over matrices 
and are the most efficient way to summarize matrix data. The R package 
[matrixStats](https://github.com/HenrikBengtsson/matrixStats) also contains 
highly optimized functions for operating on matrices.

Compare the above to the `tidy` solution given the same matrix.

```{r}
tidyr::as_tibble(m, rownames = "CpG") |>
  tidyr::pivot_longer(!CpG, names_to = "SampleName", values_to = "beta") |>
  dplyr::group_by(CpG) |>
  dplyr::mutate(n = sum(beta > 0.5)) |>
  dplyr::filter(n > 3) |>
  tidyr::pivot_wider(id_cols = CpG, names_from = "SampleName", values_from = "beta") |>
  tibble::column_to_rownames(var = "CpG") |>
  data.matrix()
```

*There's probably some kind of tidy solution using `across()` that I'm missing 
but this is how most of the tidy code in the wild that I have seen looks*

## Exploratory Data Analysis

Now that we've got a handle on some different R data types, and how to slice and 
dice them, we can start learning basic data cleaning and exploratory data analysis. 
We'll focus on using data.frames since they're the primary workhorse of data 
analysis in R. But remember, data.frames are just lists of vectors with some 
special rules, so many concepts you learn which apply to data.frames, also apply 
to vectors and lists.

### Data import

We'll use the built in `penguins_raw` dataset to learn some basic data cleaning.
This dataset is built into R version 4.5 so you can just load it by running 
`penguins_raw` if you have that R version installed. However, to illustrate 
data import, we'll read in the data from an external source.

The `read.csv()` function can read in comma-separated value files that are 
located either on your local machine or from remote sources if provided a URL.

```{r}
url <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/refs/heads/main/inst/extdata/penguins_raw.csv"
penguins <- read.csv(url)
```

The `read.csv()` function has many options for reading in data. If you want to 
learn about all of the options any particular R function has, you can prefix the 
function name with a `?` like, `?read.csv()` to bring up the help documentation.

### Taking a look at the data

The code above read the data into data.frame that we called `penguins`. We can
take a look at the first few rows of the `penguins` data.frame using the `head()`
function.

```{r}
head(penguins)
```

If we want to get a general overview of the data, we can use the `str()` function.

```{r}
str(penguins)
```

There are a few external packages that are also very useful for getting summaries 
of data.frames. `Hmsic::describe()` and `skimr::skim()` are two standouts.

One of the most basic ways to get an idea of the data is to summarize each 
variable. There are a few functions we can use to get summaries of the data. The 
`table()` function will count the number of occurrences of each type in a vector.

For example, how many observations of each species of penguin are in the dataset?

```{r}
table(penguins$Species)
```

R also provides the typical summary functions that you would expect from a 
statistical programming language such as `mean()`, `median()`, `min()`, and 
`max()`, and `length()`. 

For example, what is the mean flipper length?

```{r}
mean(penguins$Flipper.Length..mm.)
```

On no! This returned NA but there is clearly data in this column. What happened?
Missing data is commonly observed across all data domains. NAs simply represent
unknown values in this context and it's impossible to know how to take the mean of
a value that's known with a value that's unknown. It is for this reason that many 
R functions have an argument called `na.rm=`. Setting `na.rm=TRUE` in these 
functions tells R to ignore the NA values.

```{r}
mean(penguins$Flipper.Length..mm., na.rm = TRUE)
```

Now we can see that the mean flipper length is ~200 mm across all observations
in the dataset. Another useful function is `summary()`. Running `summary()` on 
a numeric vector returns a lot of useful information.

```{r}
summary(penguins$Flipper.Length..mm., na.rm = TRUE)
```

### Splitting data

You may have noticed above that we computed the mean flipper length across all
species of penguins. But do all species have the same mean? A common pattern
in R is called "split-apply-combine". This pattern means, split the data into
groups you're interested in, apply a function to each of those groups, and 
combine the results. One such function that performs this operation is called
`tapply()`. `tapply()` will split the data by a given variable into groups and 
apply a function to each group.

For example, to find the mean flipper length for each species we could use

```{r}
tapply(penguins$Flipper.Length..mm., penguins$Species, mean, na.rm = TRUE)
```

The basic format of the `tapply()` function is

```{r}
#| eval: false
tapply("data you want to compute", "what you want to group by", "function to apply")
```

Splitting can also by applied directly to data.frames using the `split()` 
function. Let's say we wanted to split the penguins data.frame into one 
data.frame for each species. We can use the `split()` function for this purpose.

```{r}
by_species <- split(penguins, f = penguins$Species)
```

This function returns a list of data.frames, one for each species in the 
original data.frame. Use the `names()` function to see what each list element 
is. To extract the first data.frame, which contains Adelie penguin data only, 
we can subset the list of data.frames. 

```{r}
adelie <- by_species[[1]]
```

### Your first plot

Data cleaning and data visualization go hand-in-hand. To effectively clean data,
you should be examining the changes you're making in real time. Base R actually
has very powerful graphics capabilities for quickly visualizing data. Packages
like [ggplot2](https://ggplot2.tidyverse.org/) and [lattice](https://lattice.r-forge.r-project.org/) provide powerful alternatives
to base R plots. We'll cover `ggplot2` later. For now, base R plotting can 
provide all we need. 





